# AlwaysOn SQL spark configuration property file
# DSE related Settings
spark.cassandra.connection.factory          com.datastax.bdp.spark.DseCassandraConnectionFactory
spark.cassandra.auth.conf.factory           com.datastax.bdp.spark.ha.alwaysonsql.auth.AlwaysOnSqlInClusterAuthConfFactory
spark.extraListeners                        com.datastax.bdp.spark.reporting.DseSparkListener,org.apache.spark.sql.hive.thriftserver.AlwaysOnSqlSparkListener
spark.SparkHadoopUtil                       org.apache.hadoop.security.DseSparkHadoopUtil
spark.hadoop.com.datastax.bdp.fs.client.authentication.factory     com.datastax.bdp.spark.ha.alwaysonsql.auth.DseFsRestClientAuthProviderFactory

spark.sql.catalogImplementation             hive
spark.sql.extensions                        org.apache.spark.sql.hive.thriftserver.AlwaysOnSqlExtensions
spark.sql.hive.metastore.barrierPrefixes    org.apache.spark.sql.cassandra
spark.sql.thriftServer.incrementalCollect   true
spark.hive.alwaysOnSql                      true


# Mutual authentication and encryption for Spark application. Unlike in standalone mode, those
# settings are per application. Authentication key is generated automatically using secure random
# number generator whenever spark.authenticate is set to true. The secret key is different for each
# single application. It is allowed to have applications running with authentication enabled and
# disabled at the same time.
spark.authenticate                          false
spark.network.crypto.enabled                false
spark.network.crypto.saslFallback           false
spark.authenticate.secretBitLength          256
spark.authenticate.enableSaslEncryption     false
spark.network.sasl.serverAlwaysEncrypt      true

# Regex to decide which Spark configuration properties and environment variables contain sensitive
# information and therefore should be redacted when they are listed in any way.
spark.redaction.regex                       (?i)secret|password|token

# When DSE Spark is started, it fetches some configuration settings from DSE node
# This operation can be retried a couple of times, as defined by this property
# The delay between subsequent retries starts from 1 second and is doubled with each trial (limited at 10 seconds)
spark.dse.configuration.fetch.retries   2

# Increase retry threshold for greater stability
spark.task.maxFailures	10

# Default AlwaysOn SQL executor memory
spark.executor.memory 1G

# Hive configuration settings in key-value pairs. It starts with spark.hive.
# spark.hive.

